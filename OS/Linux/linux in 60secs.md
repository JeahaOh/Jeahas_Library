# [Linux] 리눅스 서버 60초 안에 상황 파악하기

운영중인 시스템이 리눅스에서 작동중인데 자꾸 알 수 없이 프로세스가 죽는 등의 문제가 있었다.  
지금은 해결 했지만, 서버 컴퓨터의 상태를 확인하는데 삽질을 많이 했었고, 또 이런 일이 발생한다면, 구글링 없이 바로 찾아볼 수 있도록 기록 해 본다.  
사실 이해를 100% 한것도 아니고, 어설픈 번역이라 누군가에게 도움이 될지는 모르겠다.  
  
이 내용은 넷플릭스의 **60초안에 리눅스 퍼포먼스 상태 파악하기**라는 글의 각색 및 번역이다.  
[원문보기](https://netflixtechblog.com/linux-performance-analysis-in-60-000-milliseconds-accc10403c55)
  
리눅스 서버의 성능 이슈로 인해 원격으로 접속했을 때 먼저 체크해 봐야 할 사항.  
  
리눅스는 AWS EC2를 사용하며, 서버를 모니터링하고 성능을 체크하는데 클라우드 전체를 모니터링하는 Atlas, 하나의 인스턴스를 확인하는 Vector 등의 툴을 사용한다. 이 툴을 사용하면 대부분의 이슈는 해결 가능하지만, 가끔 인스턴스에 접속하여 성능을 체크해야할 때가 있다.
  
---
  
## 첫 60초 요약
  
1분안에 표준적인 리눅스 환경에서 CLI를 이용하여 어떤 것들을 확인할지에 대한 순서 요약이다.  
60초 안에 다음 10개 명령어를 실행하여 시스템 리소스 사용 및 실행 프로세스에 대한 높은 수준의 방안을 찾을 수 있음.  
해석하기 쉬운 오류와 포화지표를 찾은 다음 리소스 활용도를 찾음. 포화 상태는 리소스가 처리할 수 있는 것보다 더 많은 부하를 가지고 있으며 요청 대기열의 길이 또는 대기 시간으로 확인 가능할 수 있음.
  
```shell
  uptime
  dmseg | tail
  vmstat 1
  mpstat -P ALL 1
  pidstat 1
  iostat -xz 1
  free -m
  sar -n DEV 1
  sar -n TCP,ETCP 1
  top
```
  
일부 명령어는 sysstat package를 설치해야 함.  
이 측정 방법은 **[USE Method](http://www.brendangregg.com/usemethod.html)** 라고 불리는 병목현상이 생기는 위치를 찾는 방법의 일부임.  
USE는 CPU, memory, disk 등의 모든 자원에 대해서 사용율, 포화도 및 오류 메트릭을 측정하는 방법임.  
  
아래에서는 프로덕션 시스템의 예와 함께 이 명령어들을 요약이며, 명령어데 대한 자세한 설명은 해당 메뉴얼을 참고해야함.  
  
--- 
  
## uptime
  
```shell
  uptime
  11:18:48 up 18 days, 20:24,  2 users,  load average: 30.02, 26.43, 19.02
```
  
**uptime**은 현재 대기중인 프로세스가 얼마나 있는지를 나타내는 load average 값을 확인하는 가장 쉬운 방법임. Linux 시스템에서 이러한 숫자에는 CPU에서 실행하려는 프로세스와 무중단 I/O(일반적으로 디스크 IO)에서 차단 된 프로세스가 포함됨. 이는 얼마나 많은 리소스가 사용되는지 확인할 수 있지만, 다른 도구 없이는 제대로 이해할 수 없음.  
  
간단하게 살펴 보자면, 세 개의 숫자는 1, 5, 15분의 load average임.  
세 개의 숫자는 시간이 지남에 따라 부하가 어떻게 변하는 지에 대한 부하를 알 수 있음.  
예를 들어 문제가 있는 서버를 확인하라는 요청을 받았는데 1분 값이 15분 값보다 낮은 경우 너무 늦게 시스템에 접근하여 문제를 놓쳤을 수 있음.  
  
위의 예에서 load average는 1 분 값이 약 30이고 15분 값이 19정도 되는 것으로 볼 때 최근 상승한 것을 알 수 있음.  
숫자가 이렇게 크다는 것은 CPU 사용량에 문제가 있을 것으로, vmstat 또는 mpstat은 이 순서에서 실행하여 확인 해야 함.
  
---
  
## dmesg | tail
  
```shell
  dmesg | tail

  [1880957.563150] perl invoked oom-killer: gfp_mask=0x280da, order=0, oom_score_adj=0
  [...]
  [1880957.563400] Out of memory: Kill process 18694 (perl) score 246 or sacrifice child
  [1880957.563408] Killed process 18694 (perl) total-vm:1972392kB, anon-rss:1953348kB, file-rss:0kB
  [2320864.954447] TCP: Possible SYN flooding on port 7001. Dropping request.  Check SNMP counters.
```
  
dmesg는 마지막 10개의 시스템 메세지를 확인 할 수 있는 명령임.  
시스템 문제를 일으킬 수 있는 오류가 있을 수도 있음. 위 예제는 oom-killer(out of memory)와 TCP request가 드랍된 것을 알 수 있음.
항상 확인 할 가치가 있음.
  
---
  
## vmstat 1
  
```shell
  vmstat 1

  procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu-----
  r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
  1  0  58272 162580 157140 9271900    0    0     2     1    1    0  0  0 100  0  0	
  0  0  58272 162580 157140 9271900    0    0     0     0  130  222  0  0 100  0  0	
  0  0  58272 162572 157140 9271900    0    0     0     0  133  252  0  0 100  0  0	
  0  0  58272 162572 157140 9271900    0    0     0     0  101  208  0  0 100  0  0	
  0  0  58272 162696 157140 9271900    0    0     0     0  130  271  0  0 100  0  0	
  1  0  58272 162820 157140 9271900    0    0     0     0  127  264  0  0 100  0  0	
  0  0  58272 162820 157140 9271900    0    0     0     0  143  259  0  0 100  0  0	
  0  0  58272 162820 157140 9271900    0    0     0     0   93  202  0  0 100  0  0	
  0  0  58272 162804 157140 9271900    0    0     0    12  575  747  0  0 100  0  0	
  0  0  58272 162928 157140 9271900    0    0     0     0 1249 1020  1  0 99  0  0	
  1  0  58272 162804 157140 9271900    0    0     0    20 1163  975  1  0 99  0  0	
  1  0  58272 162556 157140 9271900    0    0     0     0 2743 1162  1  0 99  0  0	
  0  0  58272 161812 157140 9271900    0    0     0     0 2532  987  0  0 99  0  0	
  0  0  58272 161688 157140 9271912    0    0     0     0  122  229  0  0 100  0  0	
  1  0  58272 161812 157140 9271912    0    0     0     0  113  238  0  0 100  0  0	
  0  0  58272 161828 157140 9271912    0    0     0    40  232  331  0  0 100  0  0	
  0  0  58272 161704 157140 9271912    0    0     0     0  141  276  0  0 100  0  0	
  1  0  58272 161704 157140 9271912    0    0     0     0  103  207  0  0 100  0  0	
  0  0  58272 161688 157140 9271912    0    0     0     0  208  337  0  0 100  0  0	
  0  0  58272 161688 157140 9271912    0    0     0     0  100  213  0  0 100  0  0	
  ^C

```
  
가상 메모리 통계의 약자인 vmstat은 일반적으로 사용 가능한 명령임.  
각 행에 주요 시스템 통계 요약을 출력함.  
  
1초 요약을 출력하기 위해 vmstat에 1을 인수로 실행함.  
출력의 첫 번째 행에서는 이전 두 번째 대신 부팅 이후 의 평균을 표시하는 열이 있음.
  
- 확인 할 열
  - r :  
    CPU에서 실행 중이고 차례를 기다리는 프로세스의 수. CPU 자원의 포화(saturation)가 발생하는지 확인할 때 참고 할 수 있음.  CPU보다 큰 r 값은 포화상태임.
  - free :  
    free memory를 kb 단위로 출력. free memory가 너무 자리수가 많을 경우 충분한 공간이 있음을 의미. free -m을 이용하면 좀 더 읽기 편함.
  - si, so :  
    swap-in과 swap-out에 대한 값으로 0이 아니라면 시스템에 메모리가 부족한 것임.
  - us, sy, id, wa, st :  
    모든 CPU의 평균적인 CPU time을 측정 가능.  
    각각 user time, system time(kernel), idle, wait I/O, stolen time(가상 CPU를 서비스 하는 동안 실제 CPU를 차지한 시간을 의미) 순임.
  
CPU 시간 분석은 사용자 + 시스템 시간을 추가하여 CPU가 사용 중인지 확인함. 일정한 수준의 대기 I/O는 디스크 병목 현상을 의미. 대기중인 디스크 IO를 기다리는 작업이 차단되기 때문에 CPU가 유휴 상태임.   
  
IO 처리에는 시스템 시간이 필요함. 20% 이상의 높은 시스템 시간 평균은 더 자세히 살펴 보는 것이 권장됨. 아마 커널이 IO를 비효율적으로 처리하고 있을 수 있음.
  
CPU는 평균적으로 90% 이상 사용됨. 이는 문제는 아니지만, r 열을 확인해야함.
  
---
  
## mpstat -P ALL 1
  
```shell
  mpstat -P ALL 1
  Linux 2.6.32-431.el6.x86_64 (WAS2) 	2021년 05월 06일 	_x86_64_	(12 CPU)

  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest   %idle
  all    0.50    0.00    0.08    0.00    0.00    0.00    0.00    0.00   99.42
    0    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
    1    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
    2    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
    3    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
    4    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
    5    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
    6    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
    7    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
    8    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
    9    4.00    0.00    1.00    0.00    0.00    0.00    0.00    0.00   95.00
   10    1.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   99.00
   11    0.99    0.00    0.99    0.00    0.00    0.00    0.00    0.00   98.02
  ...
```
  
이 명령은 CPU time을 CPU 별로 출력함. 각 CPU 별로 불균형한 상태를 확인할 수 있는데, 한 CPU만 일하고 있는 것은 어플리케이션이 싱글 스레드로 동작한다는 의미임.
  
  ---
  
## pidstat 1
  
```shell
  pidstat 1
  Linux 3.13.0-49-generic (titanclusters-xxxxx)  07/14/2015    _x86_64_    (32 CPU)

  07:41:02 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command
  07:41:03 PM     0         9    0.00    0.94    0.00    0.94     1  rcuos/0
  07:41:03 PM     0      4214    5.66    5.66    0.00   11.32    15  mesos-slave
  07:41:03 PM     0      4354    0.94    0.94    0.00    1.89     8  java
  07:41:03 PM     0      6521 1596.23    1.89    0.00 1598.11    27  java
  07:41:03 PM     0      6564 1571.70    7.55    0.00 1579.25    28  java
  07:41:03 PM 60004     60154    0.94    4.72    0.00    5.66     9  pidstat

  07:41:03 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command
  07:41:04 PM     0      4214    6.00    2.00    0.00    8.00    15  mesos-slave
  07:41:04 PM     0      6521 1590.00    1.00    0.00 1591.00    27  java
  07:41:04 PM     0      6564 1573.00   10.00    0.00 1583.00    28  java
  07:41:04 PM   108      6718    1.00    0.00    0.00    1.00     0  snmp-pass
  07:41:04 PM 60004     60154    1.00    4.00    0.00    5.00     9  pidstat
  ^C
```
  
pidstat은 process 당 top 명령과 비슷한데 스크린 전체에 표시하는 것이 아니라, 지속적으로 변화하는 상황을 출력하기 때문에 상황변화를 기록하기 좋음.  
  
위 예는 CPU 자원을 차지하는 두 개의 java 프로세스를 보여줌. %CPU 열은 CPU의 합계로 1591%는 java 프로세스가 거의 16개의 CPU를 차지하고 있음을 의미함.
  
  ---
  
## iostat -xz 1
  
```shell
  iostat -xz 1
  Linux 3.13.0-49-generic (titanclusters-xxxxx)  07/14/2015  _x86_64_ (32 CPU)

  avg-cpu:  %user   %nice %system %iowait  %steal   %idle
            73.96    0.00    3.73    0.03    0.06   22.21

  Device:   rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util
  xvda        0.00     0.23    0.21    0.18     4.52     2.08    34.37     0.00    9.98   13.80    5.42   2.44   0.09
  xvdb        0.01     0.00    1.02    8.94   127.97   598.53   145.79     0.00    0.43    1.78    0.28   0.25   0.25
  xvdc        0.01     0.00    1.02    8.86   127.79   595.94   146.50     0.00    0.45    1.82    0.30   0.27   0.26
  dm-0        0.00     0.00    0.69    2.32    10.47    31.69    28.01     0.01    3.23    0.71    3.98   0.13   0.04
  dm-1        0.00     0.00    0.00    0.94     0.01     3.78     8.00     0.33  345.84    0.04  346.81   0.01   0.00
  dm-2        0.00     0.00    0.09    0.07     1.35     0.36    22.50     0.00    2.55    0.23    5.62   1.78   0.03
  [...]
  ^C
```
  
디스크(HDD, SSD 등)의 퍼포먼스를 알기 좋은 명령어임.
  
- r/s, w/s rkB/s, wkB/s :  
  장치에 전달 된 읽기, 쓰기, 읽기 속도 및 쓰기속도임. 어떤 작업이 많이 들어오는지 확인 할 수 있음.
  성능 문제는 단순히 과도한 로드(읽기나 쓰기)가 적용되었기 때문일 수 있음.
- await :  
  IO 처리 평균 시간을 밀리초로 표현한 값.  
  어플리케이션의 IO 요청이 queue에 있는 시간과 서비스 되는 시간을 모두 포함한 시간임(어플리케이션의 읽기 쓰기 소요시간). 일반적인 장치의 요청 처리 시간보다 길면 장치 포화 또는 장치 문제를 의미하게 됨.
- avgpu-sz :  
  장치에 발행 된 평균 요청수. 1보다 큰 값은 포화의 증거임.
- %util :  
  장치 사용율. 장치마다 다르지만 60% 보다 큰 값은 성능 저하를 의미함.
  
성능이 좋지 않은 디스크 IO는 어플리케이션 문제가 아닐 수 도 있음. 만은 기술이 일반적으로 IO를 비동기식으로 수행하는데 읽기를 위한 미리 읽기, 쓰기를 위한 버퍼링으로 지연 될 수도 있음.
  
  ---
  
## free -m
  
```shell
  free -m
               total       used       free     shared    buffers     cached
  Mem:        245998      24545     221453         83         59        541
  -/+ buffers/cache:      23944     222053
  Swap:            0          0          0
```
  
- buffers : Block 장치 IO의 buffer 캐시, 사용량.
- cached : 파일 시스템에서 사용되는 page cache 양.
[buffers와 cahced](https://brunch.co.kr/@alden/25)
  
위의 값들이 0에 가까워 지면 안됨. 이는 곳 높은 Disk I/O가 발생하고 있음을 의미함. (iostat으로 확인 가능함)  
위는 각각 59MB, 541MB로 괜찮은 정도임.  
  
'-/+ buffers/cache'는 사용중인 메모리와 여유 메모리 양을 의미함.  
리눅스는 빠르게 어플리케이션 메모리가 다시 할당될 수 있도록 캐시메모리를 사용함.  
따라서 캐시메모리도 여유 메모리에 포함되어 보여야 함.  
캐시메모리 또한 여유 메모리로 계산하지 않는 착각으로 인해서 [linuxatemyram](https://www.linuxatemyram.com/)란 싸이트도 있음 ㅋ.
  
---
  
## sar -n DEV 1
  
```shell
  sar -n DEV 1

  Linux 3.13.0-49-generic (titanclusters-xxxxx)  07/14/2015     _x86_64_    (32 CPU)

  12:16:48 AM     IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s   %ifutil
  12:16:49 AM      eth0  18763.00   5032.00  20686.42    478.30      0.00      0.00      0.00      0.00
  12:16:49 AM        lo     14.00     14.00      1.36      1.36      0.00      0.00      0.00      0.00
  12:16:49 AM   docker0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00

  12:16:49 AM     IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s   %ifutil
  12:16:50 AM      eth0  19763.00   5101.00  21999.10    482.56      0.00      0.00      0.00      0.00
  12:16:50 AM        lo     20.00     20.00      3.25      3.25      0.00      0.00      0.00      0.00
  12:16:50 AM   docker0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00
  ^C
```
  
rzkB/s, txkB/s를 측정할 수 있음.  
eth0의 수신량이 약 22Mbytes/s(21999.10rxkB/s)임. 이는 176Mbit/s 인데 한계인 1Gbit/s에 못 미치는 값임.  
위 값중 %ifutil은 nicstat으로도 측정 가능한 네트워크 장치 사용율임. 그러나 nicstat이라 위 예나 정확한 값을 가져오긴 어려움.  
  
---
  
## sar -n TCP,ETCP 1
  
```shell
  sar -n TCP,ETCP 1

  Linux 3.13.0-49-generic (titanclusters-xxxxx)  07/14/2015    _x86_64_    (32 CPU)

  12:17:19 AM  active/s passive/s    iseg/s    oseg/s
  12:17:20 AM      1.00      0.00  10233.00  18846.00

  12:17:19 AM  atmptf/s  estres/s retrans/s isegerr/s   orsts/s
  12:17:20 AM      0.00      0.00      0.00      0.00      0.00

  12:17:20 AM  active/s passive/s    iseg/s    oseg/s
  12:17:21 AM      1.00      0.00   8359.00   6039.00

  12:17:20 AM  atmptf/s  estres/s retrans/s isegerr/s   orsts/s
  12:17:21 AM      0.00      0.00      0.00      0.00      0.00
  ^C
```
  
TCP 측정 요약을 보여줌.
  - active/s :  로컬에서 외부로 요청한 초당 TCP 커넥션 수를 보여줌.
  - passive/s :  원격으로 요청한 초당 TCP 커넥션 수를 보여줌.
  - retrans/s :  초장 TCP 재연결 수를 보여줌.
  
active와 passive 수를 보는 것은 서버의 부하를 대략적으로 측정하는데 편함.  
localhost 끼리의 연결을 제외하면, 액티브를 아웃 바운드로, 패시브를 인 바운드로 보면 됨.
retransmits는 네트워크나 서버의 이슈가 있음 의미하는데 신뢰성이 떨어지는 네트워크 환경이나, 서버가 처리할 수 있는 용량 이상의 커넥션이 붙어서 패킷이 드랍되는 것을 의미함.  
위 예제는 초당 하나의 TCP 연결이 들어옴을 알 수 있음.
  
  
---
  
## top
  
```shell
top

top - 00:15:40 up 21:56,  1 user,  load average: 31.09, 29.87, 29.92
Tasks: 871 total,   1 running, 868 sleeping,   0 stopped,   2 zombie
%Cpu(s): 96.8 us,  0.4 sy,  0.0 ni,  2.7 id,  0.1 wa,  0.0 hi,  0.0 si,  0.0 st
KiB Mem:  25190241+total, 24921688 used, 22698073+free,    60448 buffers
KiB Swap:        0 total,        0 used,        0 free.   554208 cached Mem

   PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
 20248 root      20   0  0.227t 0.012t  18748 S  3090  5.2  29812:58 java
  4213 root      20   0 2722544  64640  44232 S  23.5  0.0 233:35.37 mesos-slave
 66128 titancl+  20   0   24344   2332   1172 R   1.0  0.0   0:00.07 top
  5235 root      20   0 38.227g 547004  49996 S   0.7  0.2   2:02.74 java
  4299 root      20   0 20.015g 2.682g  16836 S   0.3  1.1  33:14.42 java
     1 root      20   0   33620   2920   1496 S   0.0  0.0   0:03.82 init
     2 root      20   0       0      0      0 S   0.0  0.0   0:00.02 kthreadd
     3 root      20   0       0      0      0 S   0.0  0.0   0:05.35 ksoftirqd/0
     5 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/0:0H
     6 root      20   0       0      0      0 S   0.0  0.0   0:06.94 kworker/u256:0
     8 root      20   0       0      0      0 S   0.0  0.0   2:38.05 rcu_sched

```
  
top 명령어는 전반적으로 값을 확인하기 쉽고 위에서 체크한 다양한 측정치를 쉽게 볼 수 있음.  
화면지 지속적으로 바뀌기 때문에 패턴을 찾기 어려운 단점으로 다음 단축키도 사용 가능함.  
- 일시 멈춤 : ctrl + s
- 다시 시작 : ctrl + q
  
  
---
  
## ETC
  
벤치마킹, 정적 성능 튜닝, 프로파일링 등 더 깊게 알기 위해서는 더 많은 명령과 방법이 있음.  
[Linux Perfomance Tool](https://netflixtechblog.com/netflix-at-velocity-2015-linux-performance-tools-51964ddb81cf)